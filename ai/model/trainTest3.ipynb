{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 + ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImagePath = '../dataSet/splitImages/train'\n",
    "validationImagePath = '../dataSet/splitImages/val'\n",
    "testImagePath = '../dataSet/splitImages/test'\n",
    "checkpointPath = '../checkpoints/epoch_{epoch:04d}.ckpt'\n",
    "logsPath = '../logs/fit/'+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "bestCheckpointPath = '../model/best'\n",
    "\n",
    "batchSize = 32\n",
    "imageWidth = 224\n",
    "imageHeight = 225\n",
    "imageChannel = 3\n",
    "input_shape = (imageWidth, imageHeight, imageChannel)\n",
    "n_classes = 44\n",
    "scale = 30\n",
    "margin = 0.3\n",
    "dropout_rate = 0.0\n",
    "dense_units=512\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "    \n",
    "#     def get_config(self):\n",
    "#         config = super().get_config()\n",
    "#         config.update({\n",
    "#             'n_classes':self.n_classes,\n",
    "#             's':self.s,\n",
    "#             'm':self.m,\n",
    "#             'ls_eps':self.ls_eps,\n",
    "#             'easy_margin':self.easy_margin,\n",
    "#             'cos_m':self.cos_m,\n",
    "#             'sin_m':self.sin_m,\n",
    "#             'th':self.th,\n",
    "#             'mm':self.mm\n",
    "#         })\n",
    "#         return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Sequence) :\n",
    "    \n",
    "    def __init__(self,generator) :\n",
    "        self.generator = generator\n",
    "    def __len__(self) :\n",
    "        return len(self.generator)\n",
    "    def __getitem__(self,idx) :\n",
    "        x = self.generator[idx] [0]\n",
    "        y = np.argmax(self.generator[idx] [1],axis=1)\n",
    "        return (x,y),y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 데이터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator (train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataGen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range = 30,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  shear_range=20,\n",
    "                                  zoom_range=0.3,\n",
    "                                  horizontal_flip=False,\n",
    "                                  vertical_flip=False,\n",
    "                                  brightness_range=[0.7, 1.3],\n",
    "                                  fill_mode='nearest',\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5601 images belonging to 44 classes.\n"
     ]
    }
   ],
   "source": [
    "trainGenSet = trainDataGen.flow_from_directory(\n",
    "    trainImagePath,\n",
    "    batch_size=batchSize,\n",
    "    target_size=(imageWidth,imageHeight),\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 681 images belonging to 44 classes.\n"
     ]
    }
   ],
   "source": [
    "validationGenSet = trainDataGen.flow_from_directory(\n",
    "    validationImagePath,\n",
    "    batch_size=batchSize,\n",
    "    target_size=(imageWidth,imageHeight),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator (train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataGen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 739 images belonging to 44 classes.\n"
     ]
    }
   ],
   "source": [
    "testGenSet = testDataGen.flow_from_directory(\n",
    "    testImagePath,\n",
    "    batch_size=batchSize,\n",
    "    target_size=(imageWidth,imageHeight),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 02:26:35.168854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 02:26:35.281411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 02:26:35.281734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 02:26:35.282847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-15 02:26:35.283239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 02:26:35.283517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 02:26:35.283708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 02:26:36.747352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 02:26:36.747671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 02:26:36.747871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 02:26:36.748631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13690 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inp1 (InputLayer)              [(None, 224, 225, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " resnet50 (Functional)          (None, 7, 8, 2048)   23587712    ['inp1[0][0]']                   \n",
      "                                                                                                  \n",
      " head/pooling (GlobalAveragePoo  (None, 2048)        0           ['resnet50[0][0]']               \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " head/dropout (Dropout)         (None, 2048)         0           ['head/pooling[0][0]']           \n",
      "                                                                                                  \n",
      " head/dense (Dense)             (None, 512)          1049088     ['head/dropout[0][0]']           \n",
      "                                                                                                  \n",
      " inp2 (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " head/arc_margin (ArcMarginProd  (None, 44)          22528       ['head/dense[0][0]',             \n",
      " uct)                                                             'inp2[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 44)           1980        ['head/arc_margin[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,661,308\n",
      "Trainable params: 24,608,188\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backbone = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        input_shape=input_shape,\n",
    "        weights=('imagenet')\n",
    "    )\n",
    "\n",
    "pooling = tf.keras.layers.GlobalAveragePooling2D(name='head/pooling')\n",
    "dropout = tf.keras.layers.Dropout(dropout_rate, name='head/dropout')\n",
    "dense = tf.keras.layers.Dense(dense_units, name='head/dense')\n",
    "\n",
    "margin = ArcMarginProduct(\n",
    "            n_classes = n_classes, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "inp = tf.keras.layers.Input(shape = input_shape, name = 'inp1')\n",
    "label = tf.keras.layers.Input((), name = 'inp2')\n",
    "\n",
    "x = backbone(inp)\n",
    "x = pooling(x)\n",
    "x = dropout(x)\n",
    "x = dense(x)\n",
    "x = margin([x, label])\n",
    "output = Dense(44, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointPath = '../checkpoints/epoch_{epoch:04d}.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "                        checkpointPath, monitor='val_loss', verbose=0, save_best_only=False,\n",
    "                        save_weights_only=False, mode='auto', save_freq='epoch'\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = [\n",
    "                    EarlyStopping(monitor='val_loss',verbose=0, patience=10, ),\n",
    "                    ModelCheckpoint( bestCheckpointPath, monitor='val_loss', save_best_only=True )\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(logsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataSet = Dataset(trainGenSet)\n",
    "valDataSet = Dataset(validationGenSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer ArcMarginProduct has arguments ['self', 'n_classes', 's', 'm', 'easy_margin', 'ls_eps']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 02:26:58.267221: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - ETA: 0s - loss: 1.0706 - accuracy: 0.7800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0001.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0001.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1164s 7s/step - loss: 1.0706 - accuracy: 0.7800 - val_loss: 10.8960 - val_accuracy: 0.0602\n",
      "Epoch 2/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.8923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0002.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0002.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1190s 7s/step - loss: 0.4748 - accuracy: 0.8923 - val_loss: 10.3816 - val_accuracy: 0.0264\n",
      "Epoch 3/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0003.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0003.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1111s 6s/step - loss: 0.1004 - accuracy: 0.9741 - val_loss: 9.8066 - val_accuracy: 0.0073\n",
      "Epoch 4/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0004.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0004.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1114s 6s/step - loss: 0.0603 - accuracy: 0.9868 - val_loss: 8.9743 - val_accuracy: 0.0382\n",
      "Epoch 5/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0005.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0005.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1127s 6s/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 3.8975 - val_accuracy: 0.3818\n",
      "Epoch 6/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0006.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0006.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1118s 6s/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 1.9640 - val_accuracy: 0.7034\n",
      "Epoch 7/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0007.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0007.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1114s 6s/step - loss: 0.0288 - accuracy: 0.9932 - val_loss: 0.7455 - val_accuracy: 0.8267\n",
      "Epoch 8/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0008.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0008.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1122s 6s/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.1519 - val_accuracy: 0.9559\n",
      "Epoch 9/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0009.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0009.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1123s 6s/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0085 - val_accuracy: 0.9956\n",
      "Epoch 10/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0010.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0010.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1114s 6s/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 5.4512e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0011.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0011.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1095s 6s/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 1.3525 - val_accuracy: 0.7239\n",
      "Epoch 12/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0012.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0012.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1097s 6s/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 1.4493 - val_accuracy: 0.7460\n",
      "Epoch 13/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0013.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0013.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1106s 6s/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.2927 - val_accuracy: 0.9295\n",
      "Epoch 14/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0014.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0014.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1086s 6s/step - loss: 0.0333 - accuracy: 0.9923 - val_loss: 0.5116 - val_accuracy: 0.8972\n",
      "Epoch 15/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0015.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0015.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1094s 6s/step - loss: 0.0353 - accuracy: 0.9913 - val_loss: 0.0239 - val_accuracy: 0.9912\n",
      "Epoch 16/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0016.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0016.ckpt/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1108s 6s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 3.0474e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 7.3692e-04 - accuracy: 0.9996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0017.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0017.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1101s 6s/step - loss: 7.3692e-04 - accuracy: 0.9996 - val_loss: 7.5200e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0018.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0018.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1127s 6s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0106 - val_accuracy: 0.9971\n",
      "Epoch 19/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0019.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0019.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1101s 6s/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.0935 - val_accuracy: 0.9677\n",
      "Epoch 20/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0020.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0020.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1079s 6s/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.0592 - val_accuracy: 0.9838\n",
      "Epoch 21/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0021.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0021.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1085s 6s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9956\n",
      "Epoch 22/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0022.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0022.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1105s 6s/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.8678 - val_accuracy: 0.7680\n",
      "Epoch 23/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0023.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0023.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1094s 6s/step - loss: 0.0211 - accuracy: 0.9948 - val_loss: 0.8980 - val_accuracy: 0.7915\n",
      "Epoch 24/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0024.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0024.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1114s 6s/step - loss: 0.0431 - accuracy: 0.9880 - val_loss: 1.0624 - val_accuracy: 0.7959\n",
      "Epoch 25/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0025.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0025.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1091s 6s/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0026.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoints/epoch_0026.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "176/176 [==============================] - 1091s 6s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0336 - val_accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "history = model.fit(\n",
    "    trainDataSet,\n",
    "    epochs=epochs,\n",
    "    validation_data=valDataSet,\n",
    "    callbacks=[checkpoint,earlyStopping, tensorboard],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 110s 5s/step - loss: 0.0278 - accuracy: 0.9919\n",
      "[0.027843991294503212, 0.9918808937072754]\n"
     ]
    }
   ],
   "source": [
    "testDataSet = Dataset(testGenSet)\n",
    "scores = model.evaluate(testDataSet)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABR1ElEQVR4nO3dd3zTdf7A8dc7Sdt0QQe7BWllyUa2DAfiFjkVhHOBnuid4joHh3pyjtNTzx83HIfn3jhQcSGoKHqgjJaWvUcL3XSvjM/vj28KBTrSNqvp5/l45JHkm2++33eSNu98tiil0DRN0zRPMPk7AE3TNC146KSiaZqmeYxOKpqmaZrH6KSiaZqmeYxOKpqmaZrHWPwdgDtMJpMKDw/3dxiapmmtSnl5uVJK+bTw0CqSSnh4OGVlZf4OQ9M0rVURkQpfn1NXf2mapmkeo5OKpmma5jE6qWiapmke0yraVOpis9nIyMigsrLS36G0WlarlcTEREJCQvwdiqZpQaLVJpWMjAyio6Pp2bMnIuLvcFodpRT5+flkZGSQlJTk73A0TQsSrbb6q7Kykvj4eJ1QmklEiI+P1yU9TWvDROQVEckRkU31PC4i8k8R2SUiaSJyemPHbLVJBdAJpYX0+6dpbd5rwAUNPH4h0Nt1mQO80NgBW231l1sKCkApiI/3dyRaLUpBaZmDAzlFHMjLJzO/gEOFBWQX55NbVkBJRTnjrDcTa43FaoWwMI5e175d+7p9e+NiatU/kxqWmV/ID5t2snb3TrZl76HKXk3t3wU1t+vbZpEwwiQaq0QRJlFYTdGu6yiste6HmSIwm0xYLBAebry/tS/1bbNYwOFw/2K3Q1UVVFa6d22zGZ93ZCRERLh3HUjNhZsy9/LqL4uJsXSjY8gpxJlPoR0JOGwWqqo4eqmu5rj7v/89xMV5Jyal1I8i0rOBXS4D3lDGGilrRCRGRLoqpQ7X94TgTSpKQX4+FBVBaSl07+7Rb5zCwkLeeecd/vCHPzT5uRdddBHvvPMOMTExx22vqIAdO2DLlmOX7dshLy+LqKhqhgzpQVwcjV5CQtz/x967NxSz+eQv6rCw47+c6qKU8dbm5RlvdX7+sds11ztLUtkU9Q/KJJsqUz52SwGO0AIIPwJS/1o+X38YBmvuatL7ajJBbKzxGyIuzriu73ZkpPElWHMxm4+/f+I2s9l4P0ymuq9rLi11MKeYHzft5NfdO9mctZN9xTvJceykLHQXzvC843dWTThhA+/1SZRAdSRkDYOf7oedFwF+KtVaj0DXFOiSAu0PwMoFUBnr9tNDQozPuuYSFXX8/RO3dexofFUkJhqXDh2a/rmWlhr/u5s3H3+9f9gCGPrG8Ts7TVCSAIWnQNEprusex92+/PLIliQVi4isq3V/kVJqUROenwAcrHU/w7WtDSYVEejVCzIzISsLysrg1FONb0sPKCws5Pnnn68zqdjtdiyW+t/axYu/ZNu245PHli2wdy84ncY+ZrMRfr9+YLcXUl0dyY4dRuErP9/4BeMZp9b7SGho3aUCOJY4bLZ6nmypxHr+o1QO/xtmRxSRVb2IlXiiTMm0C4knxhJHXHgcnaLi6dwujq4x8STGx9GjYzwXLjmdEbev4cVPj/+lWt+v2MpK47dDfv6x9yc/Hw4dgk2bjNulpZ56vxpWO9mEhBxLSjW367p2RO1nz6DfURqZhorIOf54JBLt6E0v++UkmXoxsGtvRvXqzYQBpxIbbUUpjl6ABu9XO6oprS6lpKqE0upSymyllFSXUGorpay6lFJbieu6lOLqIr7eu4TMUy6hb/uhXJ80n9HtL8dWZT76nldWGj+Eam7bbMbfrbsXi6X2jxhFCYfZW7WB3aUp7ChJYeuRFA6W7jvu/fjHn/txdZ/fU15u/Es3dl1zKS09/n5+Puzff/y2upoXw8KOJZjayabmtt1uJI3aCeTAgeOf368fjDnDQW7fLxkcdRXXJDxCodpPgXM/efb95NkOkF25n6zKn8kufx+7sh8XQ3XsRmBwc/8k7UqpEc19cnMEb1IB4787MdH4CbJvn/GpJyXBCSWE5pg3bx67d+9m6NChTJ48mYsvvpiHHnqI2NhYtm3bxo4dO5g6dSr79h3hyJFTGT78ZkRGs3698cd8TDWxsTk4HJvo2TOXv/zlKoYODaV372P5b8GC94iKiuKee+4hNTWVW265hdJSB4mJg3nooWex29vzxhuf89VXa1Aqno4du/Lb385g//7dfPbZEsCJiJM//vFOIiOtx/1jZ2Vl0q1bQpOqIZSC0aONX3Hx8Sdf77b9zN0rb2R7/nauH3I9z57/LHHh7v/UOqPHWP538H906tTij+moqio4cuRYwikvN74Qaqphai4N3a/5cnY6G792Oo89z2ar/9pmV6zpfSPlUb/Qp/IqkkN6M6ibkTgmDjyVjjERnnsTCKUzcYB7n4XN8TRvpb3Fkz8/yfzU6fTr0I954+bx20G/JcTcsnqlrNIsVu1fxa9ZKWw4vIGUrBRyyo4l1N5xvRl7yihu7XILw7oOY1iXYYx8aSQrDyzn9rG/90qNtt0OubmQkQEHDxrXtW+vWmX8RrXbT35uTfIYNw7mzIEBA6B/f0hONpLn/w7+wvuv5HHn+b/hqoF9gD51xuBwOjhcepj9hfvZX7Sf/YX7SY71a+/MTKB7rfuJrm31CoqksnPnnZSWpja8k9NpfCumOSAsFEIbLrFERQ2ld++F9T7+5JNPsmnTJlJTjfOuXLmS9eu38Oab6WRmduPaa2Hz5o/YtcsMGL9eevZ0MHq0maKip1m48GYSE4s577xefPfdGoYOvYDp06cDwsCB19R73uuuu45//etfnHnmmfz5z3/mgw8eZuHChcycOYe9e/cSFhZGYWEhMTFw6aV3snjxPMaNG0dpaSlWq4UTC1BbtxZz2mkJDb93biqpKmH+t/N5bu1z9Gjfg6+v/prze53f5OOMTRzL+5vfJ7M4k4R2noktLAy6dDEugeTlDa/wxdJvefHiF7l5xM3+Duc4IeYQZg+bzXVDruOjrR/x+KrHmfXpLBb8sID7x93PrKGzsFqsbh2rpKqEH/b/wIo9K/h277dsyjE6G1lMFgZ0HMBFvS/i9C6nM6zrMIZ0HkJ0WPRJx5icPJkPtnyA3WnHYvL8V5fFAl27GpeRI+vex+mEnBwj0Rw8aJRIayeP+izdvhSLycIFvRpqEwezyUxiu0QS2yUyjnEteDUe8xlwm4i8B4wGihpqT4EgSSpuMZmM1rvKSqiqNn6CWsNbVBHudIbw6quwejV8//1wKiuzufJK4y3t2hXatdtJ584riIjYTG7uV7z77nuMGTOGnj2f4+KLZ1Naaic5uTtDhw4FYPjw4ezbt6/e8xUVFVFYWMiZZ54JwPXXX8+0adMAGDx4MFdffTVTp05l6tSpAIwbN467776bq6++mssvv5zExMRmv9bGLNu1jDmfz+Fg0UHmjprL45MeJyo0qlnHGpM4BoA1GWu4ov8VngwzoBwqOcQfv/kjZ55yJjcNv8nf4dTLbDIzfcB0pvWfxhc7v+DxVY/z+y9+zyM/PMI9Z9zDzcNvJjI08rjnVDuq+SXjF1bsWcGKvSv4NfNX7E47VouVCT0mcO3gazm759kM7jyYMIt7VdKTT53Mf1P+y7pD647+jfiayXTsx0l9iacuS3csZeIpE2lvbe+94JpBRN4FzgI6iEgG8DAQAqCUehH4ErgI2AWUA7MbO2ZQJJWGShR1ysszig5ms/ETI/rkX0XuOHz4z9xwg9E4fOqpNpKTv+SZZ65i5EjYuXMlDz74IBs2fENERARnnXVWnWNCwmq18ZjNZioqmjep6BdffMGPP/7I0qVLefzxx0lPT2fevHlcfPHFfPnll4wbN45ly5bRr1+/Zh2/Pvnl+dz9zd28sfEN+nXox083/MQZ3c9o0TGHdR1GmDmM1RmrgzapKKX4wxd/oMpRxX+n/BeTBH63NRHhkj6XcHHvi/l+3/c8vupx/vjNH/nrqr9y55g7Of/U81l1YBUr9qzgx/0/UmYrwyQmRnYbyX1n3Me5yecytvtYt0s3Jzon6RwEYcWeFX5LKs2x98heNudu5sZhN/o7lJMopWY28rgCbm3KMYMiqTRZhw5GqWX3bqN7VWIidO7cpFLLF190oLDwNzzwADz6KPzwQxrPPPMmU6deBcC6dUXExsYSERHBtm3bWLNmTYvDbt++PbGxsaxatYoJEybw5ptvcuaZZ+J0Ojl48CBnn30248eP57333qO0tJT8/HwGDRrEoEGDWLt2Ldu2bfNYUlFK8eGWD7ntq9soqCjggQkP8ODEB5v9hVFbqDmU4d2GszpjtQciDUwfbPmAT7d/ytOTn6ZXXC9/h9MkIsI5SedwTtI5rMlYw+OrHueh7x/ioe8fAqBfh37MHjqbc5PP5cyeZxJjjfHIeTtEdGBY12Es37OcByc+6JFj+sLnOz4H4NK+l/o5Et9om0kFjKTSv7/RgJ+RYXQP6dmz4YpRly1b4L77oujUaTNLlsykqup8Lr744uP2ueCCC3jxxRc57bTT6Nu3L2PGeOaX1euvv84tt9xCeXk5ycnJvPrqqzgcDq655hqKiopQSnH77bcTExPDQw89xPfff4/JZGLAgAFceOGFHonhUMkhbv3yVj7Z9gmndz2dZdcsY2iXoR45do0xCWN4bu1zVDuqCTWHevTY/pZXnsdtX97GyG4juXPMnf4Op0XGJI5h6cylpGWnsSV3CxN6TPBYO1hdJidP5tnVz1JaXdrs6lVfW7pjKf069Gt1Px6aTSkV8JeIiAh1oi1btpy0rVmcTqWyspRat06ptDSlysoa3L2sTKkBA5Tq2FGpzEzPhOBPTX0ff9j3g2r/RHtlfcyqnvrpKWVz2LwS1webP1AsQP2S8YtXju9PV390tQp5JESlZ6f7O5RWZ8XuFYoFqM+3f+7vUNxSVFmkQh4JUfcsu8cv5wfKlI+/rwO/ItfbRIyqr759ja4dW7cafU/rMXeuUVJ56y3o1s2HcQYApRR3L7ub2PBYNt6ykXvH3euVXjhg9AADWH0wuKrAvtjxBW+nv838CfMZ2Gmgv8Npdcb1GIfVYmX5nuX+DsUty3cvx+a0tZmqL2jlc395VFSUUR1W09aSlXVsBJnLm2/CK6/A/Plw3nl+itOPlu9ZzvrD65k/fj594uvuZ+8pCe0SSGyXyJrMlrdFBYriqmJu+eIWBnYayPwJ8/0dTqtU03tsxZ4V/g7FLUt3LCXWGtviziutiU4qtYWEGCWW2FijnWX//qND3LdtM+bgmTgRFizwb5j+8sRPT9AtuhvXDbnOJ+cbmzg2qEoq9y+/n0Mlh3h5ystB107kS5OTJ7M5dzOHSg75O5QGOZwOvtj5BRf2vtBrJfpApJPKiUwmo5tx165G1+Ndu6gosTN9ujFp3jvvuNWWH3TWZKxh5b6V/HHsH90eV9BSYxPHsr9oP4dLGhxr1Sqs3LeSF9e/yF1j7mJUwih/h9OqTT51MkDAl1Z+zfyVvPI8Lu3Tdqq+wItJpa55+kUkTkSWi8hO17X7M8P5kggkJBi9wUpKuGN2MenpRvVXgvc6tgS0J356grjwOOYMn+Ozc9YeBOlPO/N38tGWj7A765ifww3ltnJuWnoTp8aeyiNnP+Lh6NqewZ0H0zGiY8C3qyzdsRSzmBsdRR9svFlSeY2T5+mfB3yrlOoNfOu6H7g6dOCd1NN46aM4/nRDNhdMKPN3RH6xKWcTn23/jLmj5vq0G+fpXU8n1Bzq9/Eqf/jyD1z5wZUMemEQH2/9GHVCW1tjHv7+YXYV7OKlS18iIsSTc3m1TSYxMSl5Eiv2rGjyZ+FLS3csZcIpEzw2Tqe18FpSUUr9CBScsPky4HXX7deBqd46vyds3w433xnB+DMcPHJbjtGw0kDPsMZERdX9hVzf9kDxt5//RmRIJHNHzfXpecMsYZze9XS/JpW88jy+3/s9F/e+GEG4YvEVjP7vaLerXtZmruXZNc8y5/Q5nJ10tpejbTsmJ08mqzSLzbmb/R1KnfYV7mNTzqY2V/UFvm9T6ayOTUaWBXSub0cRmSMi60Rknb2uaUG9rKICpk83JiJ8930zloH9GuwZFqz2HtnLu+nvMmf4HOIjfL/Y2ZiEMaw7tI5qR7XPzw2wZOsSHMrBY+c8Rvrv03n1slfJLstm8puTmfTGJH7N/LXe51Y7qrnxsxvpGtWVpyY/5cOog9/kZKNdZfnuwKwCOzqKXicV33ENzKn3m1kptUgpNUIpNaKhtUm85a67IC0N3njDmMXlxJ5h8/7wB57797+P7r9gwQKeeeYZSktLmTRpEqeffjqDBg3i008/dfucSinuvfdeBg4cyKBBg3j//fcBOHz4MBMnTmTo0KEMHDiQVatW4XA4mDVr1tF9/+///s/TbwEAz/zvGUxi4u6xd3vl+I0Z230slfZK0rLT/HL+xVsW0yuuF0M6D8FsMjNr6Cx23LaDhecvJD07ndH/Hc3l71/OltwtJz33yZ+eJD0nnRcveTHgJhJs7bq3707f+L4B266ydMdS+sT3oXd8b3+H4nO+/rbOrlmKUkS6AjmNPsMdd94JrinoPeG9nHP4z9Y/c999cNFFtR6o6Rl26BBXjR/Pnf/4B7fecgtYLCxevJhly5ZhtVpZsmQJ7dq1Iy8vjzFjxjBlyhS31oP/+OOPSU1NZePGjeTl5TFy5EgmTpzIO++8w/nnn88DDzyAw+GgvLyc1NRUMjMz2bTJ6AdRWFjosddfI6s0i5dTXua6IdeR2M57Mxw3pPYgyBHdfLrW0NGqr/vG3Xfc5xdmCeOOMXdww7AbWLhmIU//72k+3f4p1w6+lgVnLaBnTE825WzisR8f47eDfsslfS7xadxtxbnJ5/Jq6qtU2at81iPRHSVVJazct9Ln1cWBwtcllc+A6123rwfc/xnvIzvLE7hpxz2c0XUPjz1Wxw6unmHDzj+fnNxcDq1axcZ164iNjaV79+4opZg/fz6DBw/m3HPPJTMzk+zsbLfO/dNPPzFz5kzMZjOdO3fmzDPPZO3atYwcOZJXX32VBQsWkJ6eTnR0NMnJyezZs4e5c+fy9ddf065dO8++EcDCNQuxOW3cP+5+jx/bXd3bdychOsEv7So1VV/T+k+r8/HosGgeOvMh9tyxh7vG3MV7m96jz7/6cMdXd3DDpzfQ3tqehecv9G3Qbcjk5MmU28r93jvwRMv3LKfaUd0mq77AiyWVeubpfxJYLCI3AvuB6R452cKFHjlMZSVMHwuh7eG9X5IJaWhxuw4dmDZ9Oh9++SVZxcVcNd14KW+//Ta5ubmsX7+ekJAQevbsWeeU900xceJEfvzxR7744gtmzZrF3XffzXXXXcfGjRtZtmwZL774IosXL+aVV15p0XlqK6ws5Pm1z3Nl/yv9XoQfkzjGL18cH2z5gF5xvRqdLLNDRAeeOe8Z7hh9B4/88AjPrX0Oh3Lw7hXv0jGyo2+CbYPO6nkWZjGzfM9yzux5pr/DOWrpjqXEWGPa1Cj62rzZ+2umUqqrUipEKZWolHpZKZWvlJqklOqtlDpXKXVi7zC/WrDAqEV7/XVjDerGXHXddbz3ww98+PXXTBtnrNJWVFREp06dCAkJ4fvvv2f/8WsHN2jChAm8//77OBwOcnNz+fHHHxk1ahT79++nc+fO3HTTTfzud79jw4YN5OXl4XQ6ueKKK3jsscfYsGFD8150PZ5f+zwl1SXMG+f/Xt9jE8eyt3Av2aXulfg8Ia88j+/2fse0/tPcqroEo1T10pSX2HLrFhZfuZirBlzl5SjbtvbW9oxOHB1Q7SpO5eSLHV9wYa8LW7zkcmvVBseG1+3AAaPAc911cImbVeADBgygpKKChG7d6AqQl8fVV1/NpZdeyqBBgxgxYkST1i/5zW9+w+rVqxkyZAgiwlNPPUWXLl14/fXXefrppwkJCSEqKoo33niDzMxMZs+ejdM1jcwTTzzR5Ndcn3JbOQvXLOSCXhcwrOswjx23ucZ2d7WrZKxmar+pPjlnY1VfDekT38frc6NphnOTzuWxVY9xpOIIseH+H0v9a+av5JbnttmqL0BPfV/juuuUCgtTav/+ZjzZ4VBq2zZj+vzSUo/G5W11vY//+uVfigWoH/b94IeITlZhq1Ahj4So+5ff77NzTn5jsur1z17K6XT67Jxa063av0qxAPXh5g/9HYpSSqn5K+Yr81/MqqC8wN+hKKX01Pd+s3GjMQXL7bdDjx7NOEBNr7CQENi1C2w2j8foKzaHjaf/9zRndD+DCT0m+DscwJiZdljXYT5rrG9O1ZfmH6MTRhMdGh0w84B9vvNzxvcYHxClJn/RSQW4/36IiYE//akFBwkJgV69wOEwBki6qqVam3c3vcuBogP8afyfAuoLdWziWNZmrsXm8H7CbknVl+ZbIeYQzup5VkC0q+wv3E9adlrbrvqilScV5YFR7d9+C8uWwQMPGOMaWyQiwpiEsrQUDh5scWzeduL751ROnvzpSQZ1GsTFvS+u51n+MSZxDBX2CtJz0r1+rg+2fMCpsad6fIlkzTvOTT6X3Ud2s/fIXr/GUTOKvq2PS2q1ScVqtZKfn9+ixOJ0wn33GVVet97qocDi4qBLF8jNNS4BSilFfn4+Vqv16LZPt33K1rytAVdKAd+tBFlT9TV9wPSAew+0uh2dssXPpZWlO5bSO643fTv09Wsc/tZqe38lJiaSkZFBbgu+uD//vB0bNiTw5JOZ7N1b7LnglIKyMli/3kgwYYEz2rc2q9VKYqIxUl4pxRM/PUFybDLTBgRetU+P9j3oGtWV1RmruXWUp34BnOyTbZ/oqq9Wpl+HfiREJ7BizwqfLs1QW2l1Kd/v+57bRt7ml/MHklabVEJCQkhKSmr286uq4PnnYehQuPfeBEwmDy+UcuQIjBoFJSVGcgnwhVi+2/sdaw+t5cWLXwzIVepExCeDIBdvXqyrvloZEWHyqZP5bPtnOJwOzCazz2NYvtsYRd/Wq76gFVd/tdTzz8O+ffC3vxmdtzwuNhY++cQosfzmN8Zw/QD2xE9P0CWqC9cPvb7xnf1kbOJYdh/ZTU6ZZ6aMO5Hu9dV6nZt0LgUVBaRkpfjl/Et3LKV9WHvG9xjvl/MHkjaZVAoL4bHHYPJkOO88L55owACjr/LatXDLLQE7Xf7azLV8u/db7h5zN1aLtfEn+EnNIEhvlVZqqr6mD/DM7EGa75ybfC7gn6nwncp5dC36tjqKvrY2mVT+9jcoKDCuvW7qVHj4YWPul3/9ywcnbLonfnqCGGsMt4y4xd+hNGh41+FYTBavJRVd9dV6dY7qzODOg/3SWL82cy05ZTlc0ltXfUEbTCoHDxrTsVxzDQzz1Qwkf/4zXHYZ3H03fP+9j07qnq25W1mybQm3jbyN6LBof4fToPCQcIZ2GeqVQZC66qv1m5w8mZ8P/ky5rdyn561Zi/7C3hf69LyBqs0llYcfNroSP/qoD09qMhmrffXpA9OmweHDjT/HR578+UkiQiK4Y8wd/g7FLWMTx/Jr5q/YnZ5dDfRor68A7Pmmuefc5HOpdlSzav8qn5738x2fM67HOOLC43x63kDVppJKerpRC3XbbcYYRZ9q185oX8nPN0ZbBoBdBbt4O+1tbh5+Mx0iOvg7HLeMSRxDua2c9GzPDoKsGfA4rIv/J9DUmmfiKRMJNYf6tArsQNEBNmZv1FVftbSppDJvnvHd/sADfgpg0CCj1LLXvyN/azy+6nFCzCHcN+4+f4fitppBkJ5sV8krz+PbPd/qqq9WLiIkgnHdx/k0qRxdi75v256apbY2k1RWroQvvzTm94rzVyk1NNRYqGXPHj8FcMzugt28ufFNbh5+M12iuvg7HLf1jOlJ58jOHm1X0VVfwWNy8mTSstN8tvbO5zs+p1dcL/rGt85R9CJygYhsF5FdInLS4kki0kNEvheRFBFJE5GL6jpObW0iqTidcO+9kJgIc/29bHRyckAklSd+egKLydKqSilwbBCkJ5PKB1s+IDk2WVd9BYGarsXf7v3W6+cqqy7ju73fcUnvS1plCVdEzMBzwIVAf2CmiPQ/YbcHgcVKqWHADOD5xo7bJpLKBx/AunXG2JTwcD8HEwBJZV/hPl7f+Dpzhs+hW3Q3v8bSHGMTx7KrYBd55XktPlZ+eT7f7vmW6f31XF/B4PSupxNrjfVJFdjyPcupclS15qqvUcAupdQepVQ18B5w2Qn7KKCd63Z74FBjBw28+Tg8rLoa5s83mjOuucbf0QBJSZCVBeXlxqzGfvDXVX/FJCbuH3e/X87fUrUHQbZ0Wowl25boqq8gYjaZmZQ8ieW7l6OUavIPhUp7Jfnl+RRUFFBQUUB+hXG7ZlvN/YKKArbnb6ddWLuAWXeoHhYRWVfr/iKl1CLX7QSg9nTqGcDoE56/APhGROYCkcC5jZ6w+bG2Di++aBQMvvoKzL6fEuhkycnG9b590P/Ekqb37S/cz6uprzLn9DkktAvs+cjqM7zrcMxiZvXB1S1OKrrqK/hMTp7Mh1s+ZFveNk7reFqj++85sofXUl/j9Y2vc6DoQL37hZnDiI+IJy48jrjwOMYmjuXSPpcG+ih6u1JqRAuePxN4TSn1dxEZC7wpIgOVUvUuGBXUSaW42BiPcs45cP75/o7GpSap7Nnjl6TyxE9PIAjzxp/UJtdqRIZGMqTLENZktqwHWE3V1z1n3KOrvoJITbvKij0r6k0qFbYKPt76Ma+kvsJ3e79DEM7vdT43D7+Z+PD4o8kjPtx1HRFPuCU82P5OMoHute4nurbVdiNwAYBSarWIWIEOQL0T8AV1UnnqKcjLM64D5m+hdlLxsQNFB3gl5RVuHHYj3dt3b/wJAWxs4lhe3/h6i2al1XN9Bafk2GSSY5NZvmc5c0cf65mjlGL94fW8vOFl3t30LkVVRSTFJPHo2Y9y/ZDrW/3/RDOsBXqLSBJGMpkB/PaEfQ4Ak4DXROQ0wAo0uN5IUCeV0lKjHWX4cH9HUkuHDhAV5Zek8uRPTwLwpwktWTc5MIxNHMtza59jU84mhnQZ0qxjLN6yWFd9BanJyZN5J/0dbA4bRVVFvJ32Ni+nvEx6TjpWi5Ur+1/JDUNv4MyeZ2KSNtFf6SRKKbuI3AYsA8zAK0qpzSLyCLBOKfUZ8EfgJRG5C6PRfpZqZGXEoE4qCxcG4FLxIn7pAZZRnMHLKS8ze+hserTv4dNze8OYxDGA0VjfnKSiq76C2+Tkyfxn/X84763z+PnAz9icNkZ2G8kLF7/AjIEziLHG+DvEgKCU+hL48oRtf651ewswrinHDOqkAl5aK6WlkpJg1y6fnvLJn57EqZxBUUoBo4qjY0RHVmes5uYRNzf5+XqFx+B2dtLZRIZEkp6dzq0jb+WGYTcwqPMgf4fVJgR9UglIycmwfLmxvooPfiVnFmfy0oaXmDVkFj1jenr9fL4gIoztPrbZgyBren2d3vV0D0emBYK48Dh2376b2PBYQs2h/g6nTQnE3/HBLznZGKeS450VDE/01M9P4VRO5k+Y75Pz+cqYhDHsyN9Bfnl+k56XX57Pij0r9FxfQa5zVGedUPxAJxV/8GEPsMMlh1m0YRHXDb6OpNgkr5/Pl2oGQf6S+UuTnqervjTNe/ySVETkLhHZLCKbRORdV9/ntsOHSeWpn5/C5rAFXSkFYGS3kZjExOqD7lWBHS45zP+t/j8e/fFRXfWlaV7i8zYVEUkAbgf6K6UqRGQxRv/o13wdi9/ULObi5aSSVZrFi+tf5JrB13Bq3KlePZc/RIZGMrjz4AbbVUqrS/lk2ye8mfYmK/aswKmcjOg2gicmPaGrvjTNC/zVUG8BwkXEBkTgxiRlQcVqhW7dvJ5Unv75aaod1TwwwV8LyHjf2MSxvJX21nGDIO1OOyv2rOCttLdYsm0J5bZyesb0ZP74+Vw9+Gr6dejn56g1LXj5PKkopTJF5BmMkZoVwDdKqW9O3E9E5gBzAEJDg7CxLTnZq4t1ZZdm88K6F7h60NX0ju/ttfP429jEsbyw7gW25G6h2lHNW2lv8e6md8kuyybWGsu1g6/lmsHXcEb3M9rsIDdN8yV/VH/FYkyvnAQUAh+IyDVKqbdq7+eaSXMRQGRkZIMjOFul5GT4/nuvHf6Z/z1DlaOKByc+6LVzBIKaQZBnvX4WBRUFhJpDuaTPJVw7+Fou7HUhYZYw/waoaW2MP6q/zgX2KqVyAUTkY+AM4K0GnxVskpONNeurqiDMs198OWU5PL/ueWYOnEmf+D4ePXag6RXXi/E9xiMI1w6+liv7X0lseKy/w9K0NssfSeUAMEZEIjCqvyYB6xp+ShBKTjYGP+7fD308+8X/9//9nQpbRdCXUsAYBLlq9ip/h6FpmovPK5mVUr8AHwIbgHRXDIsafFIw8lK34rzyPJ5b+xwzBs7QDdKapvmcX3p/KaUeBh72x7kDRpJrIKKHk8qzq5+l3FbOQxMf8uhxNU3T3KG7w/hLly5G12IPJ5W30t7i0r6XurXinaZpmqfppOIvJpNRWvFgt+K88jwOFh8M9DWzNU0LYjqp+JOH11VJzUoF0ItOaZrmNzqp+FNNUml4ITW3pRxOAWBol6EeOZ6maVpT6aTiT8nJUFwMBQUeOVxqdird23UnPiLeI8fTNE1rKp1U/MnDPcBSDqcwrKuu+tI0zX90UvEnD45VKbeVsz1/u25P0TTNr3RS8aeakooHeoClZ6fjVE7dnqJpml/ppOJPUVHQqZNHSiopWUYjvS6paJrmTzqp+JuHuhWnHE4h1hpLj/Y9PBCUpmla8+ik4m+eSipZKQztMlSvZqhpml/ppOJvSUlw4ADYbM0+hN1pJz0nXVd9aZrmdzqp+FtyMjgccPBgsw+xPW87lfZK3Z1Y0zS/00nF3zzQrbimkV73/NI0zd90UvG3mqTSgm7FqVmpWC1WvX6Kpml+p5OKvyUkQEhIi0sqgzoNwmLyy/I4mqZpR+mk4m9mM/Ts2eykopQi5XCKrvrSNC0g6KQSCJKSmp1UDhYf5EjlEd3zS9O0gKCTSiBowViVmunudc8vTdOaSkQuEJHtIrJLRObVs890EdkiIptF5J3Gjqkr4QNBcrIx/X1hIcTENOmpKVkpCMKgToO8EpqmacFJRMzAc8BkIANYKyKfKaW21NqnN/AnYJxS6oiIdGrsuLqkEgha0AMsNSuVvh36Ehka6eGgNE0LcqOAXUqpPUqpauA94LIT9rkJeE4pdQRAKZXT2EF1UgkELUgqKVkpuj1F07T6WERkXa3LnFqPJQC1R11nuLbV1gfoIyI/i8gaEbmg0RO2PGatxZo5ADK/PJ8DRQe4deStXghK07QgYFdKjWjB8y1Ab+AsIBH4UUQGKaUK63uCLqkEgvbtITa2yUllY/ZGQE93r2las2QC3WvdT3Rtqy0D+EwpZVNK7QV2YCSZeumkEiia0QOspueXHqOiaVozrAV6i0iSiIQCM4DPTtjnE4xSCiLSAaM6rMEvKp1UAkVzkkpWCgnRCXSM7OiloDRNC1ZKKTtwG7AM2AosVkptFpFHRGSKa7dlQL6IbAG+B+5VSuU3dFzdphIokpPhk0+MGYvNZreekpqVqsenaJrWbEqpL4EvT9j251q3FXC36+IWv5RURCRGRD4UkW0islVExvojjoCSnGysqXLokFu7V9gq2Ja3TbenaJoWUPxV/fUP4GulVD9gCEbRq21rYg+w9Jx0HMqh21M0TQsoPk8qItIemAi8DKCUqm6oe1qbkZRkXLuZVFKzUgHd80vTtMDij5JKEpALvCoiKSLyXxE5aTi4iMypGbBjt9t9H6Wv9egBJpPbSSXlcArtw9rTM6and+PSNE1rAn8kFQtwOvCCUmoYUAacNJGZUmqRUmqEUmqExdIG+hOEhBiJxd2kkmVMdy8iXg5M0zTNff5IKhlAhlLqF9f9DzGSjOZmt2KH00Fadpqu+tI0LeD4PKkopbKAgyLS17VpErClgae0HW4mlR35O6iwV+hGek3TAo5bSUVE7hCRdmJ4WUQ2iMh5LTjvXOBtEUkDhgJ/bcGxgkdyMuTkQFlZg7ulZOk1VDRNC0zullRuUEoVA+cBscC1wJPNPalSKtXVXjJYKTW1ZlrlNq+mB1gjsxWnZqUSag7ltA6n+SAoTdM097mbVGpagy8C3lRKba61TfMUN8eqpGSlMLDTQELMIT4IStM0zX3uJpX1IvINRlJZJiLRgNN7YbVRbiQVpRQph/UaKpqmBSZ3++reiNH2sUcpVS4iccBsr0XVVsXHQ3R0g0klsyST/Ip8nVQ0TQtI7pZUxgLblVKFInIN8CBQ5L2w2iiRRnuA6enuNU0LZO4mlReAchEZAvwR2A284bWo2rLk5AYb6lOyUhCEIV2G+DAoTdM097ibVOyuKZAvA/6tlHoOiPZeWG1YUpJRUlGqzodTs1LpHd+bqNAoHwemaZrWOHeTSomI/AmjK/EXImICdNcjb0hOhspKyMqq8+Ga6Vk0TdMCkbtJ5SqgCmO8ShbGWsZPey2qtqyBHmBHKo6wr3CfbqTXNC1guZVUXInkbaC9iFwCVCqldJuKNzSQVDZmbwT0dPeapgUud6dpmQ78CkwDpgO/iMiV3gyszTrlFKMXWB1JRff80jQt0Lk7TuUBYKRSKgdARDoCKzBmGNY8yWqFhIS6k0pWCl2jutI5qrMfAtM0TWucu20qppqE4pLfhOdqTZWUVGe34tSsVD2JpKZpAc3dxPC1iCwTkVkiMgv4AvjSe2G1cXUMgKy0V7IldwtDOw/1T0yapmlucKv6Syl1r4hcAYxzbVqklFrivbDauORkyMw0uhZbrQBsytmEQzl0SUXTtIDm9jq9SqmPgI+8GItWo6YH2L590K8fYFR9ge75pWlaYGswqYhICVDX0G4BlFKqnVeiautqdyt2JZWUwylEh0aTFJvkx8A0TdMa1mBSUUrpqVj8oY6xKjUj6U2i+0domha49DdUIOrcGcLDj/YAczgdpGWn6aovTdMCnk4qgUjk2MSSwK6CXZTZyvSgR03TAp5OKoGqVrfilCxjJL3u+aVpWqDTSSVQ1SQVpUjNSiXEFEL/jv39HZWmaVqDdFIJVMnJUFoKeXmkZKUwoNMAQs2h/o5K0zStQTqpBCpXDzC1ezcph1N0I72maR4nIheIyHYR2SUi8xrY7woRUSIyorFj6qQSqJKM8SiHd24gtzxXJxVN0zxKRMzAc8CFQH9gpoicVMcuItHAHcAv7hxXJ5VA5UoqKfvXAHq6e03TPG4UsEsptUcpVQ28h7Fk/IkeBf4GVLpzUJ1UAlVkJHTuTErBZgCGdBni54A0TWuFLCKyrtZlTq3HEoCDte5nuLYdJSKnA92VUl+4fcIWhat5V3IyqdW76BXXi3ZhekYcTdOazK6UarQdpC4iYgKeBWY15Xl+K6mIiFlEUkTkc3/FEPCSk0kJO6KrvjRN84ZMoHut+4mubTWigYHAShHZB4wBPmussd6f1V93AFv9eP6AV5ycwJ52doZ2GOTvUDRNCz5rgd4ikiQiocAM4LOaB5VSRUqpDkqpnkqpnsAaYIpSal1DB/VLUhGRROBi4L/+OH9rsambUTs5RLr4ORJN04KNUsoO3AYsw/iBv1gptVlEHhGRKc09rr/aVBYC92EUr+rkalCaAxAa2jYH/aW1q4BsGFQS4e9QNE0LQkqpLzlhFV+l1J/r2fcsd47p85KKiFwC5Cil1je0n1JqkVJqhFJqhMXSNvsTpJvzaVcJPTJL/R2KpmmaW/xR/TUOmOJq+HkPOEdE3vJDHAEvrWw3g/LNyM8/+zsUTdM0t/g8qSil/qSUSnQ1/MwAvlNKXePrOAKdUor0nE0Mbt8bPvkEysv9HZKmaVqj9ODHAHWw+CBFVUUMGnKeMbHkF26PPdI0TfMbvyYVpdRKpdQl/owhUKVlpwEwePwVxkqQ773n54g0TdMap0sqASo9Ox2AgV2GwPTpRkmlqMjPUWmapjVMJ5UAlZaTxintT6G9tT3MnAlVVUbbiqZpWgDTSSVApWenM7jzYOPOmDHQsye8+65fY9I0TWuMTioBqMpexba8bQzq5JqeRQRmzIAVKyA317/BaZqmNUAnlQC0LW8bDuU4VlIBowrM4YAPPvBfYJqmaY3QSSUA1fT8GtS51kSSgwZB//66CkzTtICmk0oASs9JJ9QcSp/4Psc21lSB/fQTHDxY/5M1TdP8SCeVAJSWnUb/jv2xmE6Y82zmTOP6/fd9H5SmaZobdFIJQOk56ce3p9To1QtGjNBVYJqmBSydVAJMXnkeh0oOHev5daKZM2HDBtixw7eBaZqmuUEnlQBTM5K+zpIKwFVXGe0rurSiaVoA0kklwKTnNJJUEhJg4kQjqSjlw8g0TdMap5NKgEnLTqNDRAc6R3auf6eZM2H7dkhN9VlcmqZp7tBJJcDUNNKLSP07XXEFWCx65mJN0wKOTioBxKmcbMrZVH8jfY0OHWDyZCOpOJ2+CU7TNM0NOqkEkD1H9lBuK6+/PaW2mTPhwAFYvdr7gWmaprlJJ5UAcnR6lsZKKgBTp4LVqnuBaZoWUHRSCSDp2ekIwoBOAxrfOToaLrnEmGDSbvd+cJqmaW7QSSWApOWk0SuuFxEhEe49YeZMyMmB777zbmCapmlu0kklgKRlp7nXnlLjoouMEouuAtM0LUDopBIgyqrL2F2wu2lJxWqF3/wGPv7YWG5Y0zTNz3RSCRCbczejUO410tc2cyYUF8NXX3knME3TtCbQSSVANDrnV30mTTLGregqME3TAoBOKgEiLTuNyJBIkmKTmvbEkBCYNg2WLoXSUu8Ep2ma5iadVAJEek46AzsNxCTN+EhmzoSKCvj0U88Hpmma1gQ6qQQApRRp2WlNb0+pMW4cJCbqKjBN05pERC4Qke0isktE5tXx+N0iskVE0kTkWxE5pbFj6qQSALJKs8ivyG96e0oNk8lYv37ZMigo8GxwmqYFJRExA88BFwL9gZki0v+E3VKAEUqpwcCHwFONHdfnSUVEuovI967st1lE7vB1DIHm6PQsnZtZUgGjCsxuh48+8lBUmqYFuVHALqXUHqVUNfAecFntHZRS3yulyl131wCJjR3UHyUVO/BHpVR/YAxwax3ZsU2pWZir2dVfAMOGQe/eugpM0zR3JQAHa93PcG2rz41Ao2MXfJ5UlFKHlVIbXLdLgK00/EKCXlp2GgnRCcRHxDf/ICJGaWXlSjh0yGOxaZrWqllEZF2ty5zmHERErgFGAE83tq9f21REpCcwDPjFn3H4W1p2WsuqvmrMnGksMbx4ccuPpWlaMLArpUbUuiyq9Vgm0L3W/UTXtuOIyLnAA8AUpVSjU3f4LamISBTwEXCnUqq4jsfn1GRXexDPwmtz2Niat5XBnZrZSF9bv34wYgT885962hZN0xqzFugtIkkiEgrMAD6rvYOIDAP+g5FQctw5qF+SioiEYCSUt5VSH9e1j1JqUU12tVgsvg3Qh3bk76DaUe2ZkgrAY4/B3r3w/POeOZ6maUFJKWUHbgOWYTRDLFZKbRaRR0Rkimu3p4Eo4AMRSRWRz+o53FGilPJa0HWe0Fh8/XWgQCl1pzvPiYyMVGVlZV6Ny1/e2/QeMz+aycZbNja/S/GJzjsP1q2D3bshNtYzx9Q0rdURkXKlVKQvz+mPkso44FrgHFfmSxWRi/wQR0BIy07DYrLQr0M/zx306aehsBCeeMJzx9Q0TXODz+uVlFI/AeLr8waq9Jx0+nXoR6g51HMHHTIErrvOaFu59VY4pdFBsJqmaR6hR9T7WYumZ2nIY48Z3YwfeMDzx9Y0TauHTip+VFRZxIGiA55rS6ktMRHuugvefhvWr/f88TVN0+qgk4of1Yyk90pSAbj/fmOtlXvvNcavaJqmeZnPe381R129v2w2GxkZGVRWVvopqpYrqSqhoKKAhHYJWExeat4qKTEmmezUCcLDvXOOBlitVhITEwkJCfH5uetVWAgRERDqwXYsTQtA/uj91WoHgGRkZBAdHU3Pnj0xeim3PvsL9xNSEcLALgO99xqcTti82Whf6dfPuPYRpRT5+flkZGSQlNTExcdaqqgIdu40Lrt2Hbu9cyfk58M558CKFT59PzStLWi1SaWysrJVJxSACnsF4SHh3n0NJpPRvrJ7N+TlQceO3jvXCUSE+Ph4cnNzvXuiX34xEkTtxHHiObt3NybcvOIKsNng1Vfhgw9g+nTvxqZpbUyrTSpAq04oSinKbeV0iOjg/ZPFxEBUlDHRZFwcmM3eP6eL1z+jvXth/Hhj2v9u3YzEcdllxnXN5dRTj6/6czggJcVoa7rkEqMqTNM0j2jVSaU1q3ZU41ROwi0+aOcQMUor27ZBdrbx5Rss/vpXI0nu2uX+eByzGf7xDzjzTGOg6MMPezdGTWtDdO+vZiosLOT5Zs6vddFFF5GVlwVAeIiPGs+joowpW7KyjOqfYLBvH7z2Gtx0U9MHeE6caFR9/e1vcOCAN6LTtDZJJ5VmaiipNDar8pdffklopNHzyCcllRoJCUbX4nrWW1FK4XQ6fRdPSz3xhNFmdP/9zXv+008b78d993k2Lk1rw4Iiqdx5J5x11smXM890cuaZjjofa+xy550Nn3PevHns3r2boUOHcu+997Jy5UomTJjAlClT6N/fWMhy6tSpDB8+nAEDBrBo0bFlDHr27ElGVgZ5mXkMHDCQm266iQEDBnDeeedRUVFx0rmWLl3K6NGjGTZsGOeeey7Z2dkAlJaWMnv2bAYNGsTgwYP5yLWU8Ndff83pp5/OkCFDmDRpEgALFizgmX//22ioz81l4IAB7Nu3j3379tG3b1+uu+46Bg4cyMGDB/n973/PiBEjGDBgAA/Xqhpau3YtZ5xxBkOGDGHUqFGUlJQwceJEUlNTj+4zfvx4Nm7c2Ohn1mIHDhiN7b/7nVG11xw9ehgJ6f33YdUqz8anBb/qauOiHSeI21QUTmcl4MBkCkfEsy/1ySefZNOmTUe/UFeuXMmGDRvYtGnT0e6zr7zyCnFxcVRUVDBy5EiuuOIK4uON1R0r7ZVYQ6zs3LmTd999l5deeonp06fz0Ucfcc011xx3rvHjx7NmzRpEhP/+97889dRT/P3vf+fRRx+lffv2pKcbgyiPHDlCbm4uN910Ez/++CNJSUkUFBQcH3jXrkaX2lpVYDt37uT1119nzJgxADz++OPExcXhcDiYNGkSaWlp9OvXj6uuuor333+fkSNHUlxcTHh4ODfeeCOvvfYaCxcuZMeOHVRWVjJkyBCPvtd1qpksc968lh3nvvvglVfg9tuNmZ192IlBa2XKy2HNGvjhB/jxR+N2377w6696zFMtQZFUFi6sa6vgdJqpqNiD01mF1ZpESEicV+MYNWrUceMx/vnPf7JkyRIADh48yM6dO48mlSpHFVHmKJKSkhg6dCgAw4cPZ9++fScdNyMjg6uuuorDhw9TXV199BwrVqzgvffeO7pfbGwsS5cuZeLEiUf3iYs74TWHhECXLkYPqNJSiIrilFNOOZpQABYvXsyiRYuw2+0cPnyYLVu2ICJ07dqVkSNHAtCuXTsApk2bxqOPPsrTTz/NK6+8wqxZs5r/Brrr4EF4+WW48Uajq3BLREQY1WAzZhjJ5aabPBOj1vqVlMD//mckkR9+gLVrjR9jJhMMHQrTpsGbbxrtcg895O9oA0ZQJJX6mExhhIf3o6JiF5WVe1DKRmhoZ6+dLzLy2MDVlStXsmLFClavXk1ERARnnXXW0dH/CmMWA2uIlbCwsKPPMZvNdVZ/zZ07l7vvvpspU6awcuVKFixY0OTYLBbLsfaSzp2ptNng8GHo1eu4uPfu3cszzzzD2rVriY2NZdasWQ3OWhAREcHkyZP59NNPWbx4Met9Mc9YTSnlT3/yzPGmT4fnnoP5840vipgYzxxXax1sNigrM5LIxo3HksiGDcaPL7PZWFH1rruMHoPjxkH79sZzq6uNyVunTTMGF2vB0abSEJPJQkREHyyWGKqqDlJZeRBPTE0THR1NSUlJvY8XFRURGxtLREQE27ZtY82aNUcfqzm/1Wx161xFRUUkJCQA8Prrrx/dPnnyZJ577rmj948cOcKYMWP48ccf2bt3L8DR6q+ePXuyYcMGADakprI3MxMqKowpS2opLi4mMjKS9u3bk52dzVdffQVA3759OXz4MGvXrgWgpKTkaIeE3/3ud9x+++2MHDmSWG8vCpaRYZRSZs822kQ8QcToYpyfD4884pljav7ldMIzzxhtbjNmwKWXwtlnw8iR0L+/8bcTHw9hYUbVVWysse3SS40lI8LCjKrVb74x/kfWrDFKJBdddCyhgPF3ExkJc+YY59SCu6RSQ8SE1XoqVVUHsdmyUcqG1doTkebn1Pj4eMaNG8fAgQO58MILufjii497/IILLuDFF1/ktNNOo2/fvsdVLymlEIQwS9iJh63TggULmDZtGrGxsZxzzjlHE8aDDz7IrbfeysCBAzGbzTz88MNcfvnlLFq0iMsvvxyn00mnTp1Yvnw5V1xxBW+88QYDBgxg9OjR9OnTxxgQmJV13LmGDBnCsGHD6NevH927d2fcuHEAhIaG8v777zN37lwqKioIDw9nxYoVREVFMXz4cNq1a8fs2bOb/X667cknjX9eT5VSagwbZlR9/etfxvVpp3n2+JpvPfII/OUvRhtiu3bGF39kpNFRpWdPo4t9ZOTJ1717w5gx7s+T17mzkbxuvNH4saOrT1vvhJJbt27ltCb+4yulqK7Opro6A7M5Gqv1VEzemsixATvyd2B32unfsb/Pz32c4mLYscPoPdWlS7MPc+jQIc466yy2bduGyXRyom7OZ1WnzExITjYWIHvppZYf70S5uce+VL76Ss8L1lotXQpTphil2Zdf9v7nqJQxl1xKCmzdaiSyANFWlhP2GxEhLKwLVmsSDkcpFRXbcTp93yWwwlbhu0GPDWnXzijKZ2YaVT/N8MYbbzB69Ggef/zxOhOKR/3tb0YpZf587xy/Y0dYsACWLYMvvvDOOTTv2rkTrrkGhg832sl88cNABBYtgspKoxdhG9emSiq12e3FVFTsQsRMeHhvzGbfzP9kc9jYmL2RxHaJdIlqfunAY+x2Y7LJkhJjcGSXLh7/R/RISeXQIaOUcvXVxq9Pb7HZYPBg433ZvFl3FW1NSkuNUmZWlrEwna+X0f7rX42VVj/91CgpBQBdUvGw4qpiSqtL63zMYmlHRITRW6O8fDt2e7FPYqqwG727IkICZBJDi8Wo8omLM0osBw4E5oJeTz1lfNF7e3nkkBCjj/quXUYjrNY6KGW0a2zdCu+95/uEAsYEpQMHwq23GlXLbVRQJ5VDJYfYlreN3QW7qbSf3C3WbI4gIqIfJlMIFRU7sdkK6jiKZ1XYjKTi0+lZGmMyQVKSUUrJzTVKLg6Hv6M65vBh+M9/jLaU5GTvn+/8843Zix999KSODG5RSo+09rW//x0WLzY6cpx7rn9iCAmB//7X+HHm7R8/ASyok0rvuN50i+5GUVURm3M2c7DoIHbH8fNy1YxlMZsjqazcQ1XVYY90Oa5Phb0Ci8lCiDmAVkKEYzMZ9+hhdKHcsSNwJp58+mkjFl/+oz77rFFH7m77jdMJP/1kzO/To4fRXvXPfwZmqS/YfPedMd3OlVfCPff4N5bRo+G224z2nNWr/RuLn7SJNpVqRzWHSg6RV56HWcx0je5Kp8hOmGp1KVbKSWXlXuz2I5hM4YSFJWKxtG/gqM2zJXcLFpOFPvF9PH5sjyksNEoroaFG1ZjVvfE09WlRm0p2tlGKmj7dmJHYl+67z0hov/5qjG84kd1uTNfx0Ufw8cdGqSYsDM47D6qqjDEOl1xizFHWwQfr5rRFBw4YjfKdOhljSaKj/R2R0T7Zv78xiHb9er+2y+k2FS8JNYfSM6YnAzoOICo0ioziDDblbCK/PP9oqcQYy5KM1ZqMUk4qKnZSXr4Dh6PcY3FERUVRaa8MrKqvusTEGHMaORzGGiwnJHSfevpp4wvaH9UJDz5ojEO4445jJQ6bzegddtNNRtfRSZOMpDFuHLz7rlF9+Nln8PXXRtvMN98YDf/ffef7+INdZSVcfrlR1bhkSWAkFDDieP552LTJ+Ptta5RSAX+JiIhQJ9qyZctJ29xVVFmkNudsVmsz16rNOZtVcWXxcY87nQ5VVZWlios3qOLitaq8fK9yOKqafT6llKq2V6uIyAi1NnOtyi3LbdGxmstmszXtCRUVSqWlKbV+vVJHjjT7vM3+rLKzlQoPV+raa5t97hZ75RWlQKn771fq+uuViokx7kdFKTVzplIffqhUaWn9z09JUapvX6VElJo/X6nqal9FHtycTqVmzzY+i08/9Xc0dZs2TamwMKW2b/dbCECZ8vH3dVCMqL/z6ztJzUpt8vNsThvV9mqcOLGYLISZw45WiQ3tMpRnz3uG6urD2Gw52O0FhIZ2ITS0MyJm5s2bR/fu3bn11lsBY9R7VFQUt9xyC5dddhlHjhzBZrPxl0f+wqhJo8gpy0EpRVx4HLHW46cymTp1KgcPHqSyspI77riDOXPmAMYU9vPnz8fhcNChQwe+/fZbSktLmTt3LuvWrUNEePjhh7niiiuIioqitNTo6fbhhx/y+eef89prrzFr1iysVispKSmMGzeOGTNmcMcdd1BZWUl4eDivvvoqffv2xeFwcP/99/P1119jMpmOTsf/z4UL+eTJJ2HXLpbv3cvz77xzdJJMr3vmGaOU8uCDvjlfXa6/Hl54wRgjExNjdBW98kqYPNm9asGhQ40qkDvuMLqcfvcdvPOOUaWnNd+iRUYJ8aGHAqb77kn++U9YvtyYwuX779vMYNqgSCrNFWIKISQ0hGpHNdWOasqcZYSYQrCYLCgUJpMFq7U7ISEdqa7OpLr6EDZbLqGhCUyfPp277rrraFJZvHgxy5Ytw2q1smTJEiKiIti6fysXnXMRH//0MXHhcZjERHLsyb2X6poi3+l01jmFfV3T3TcmIyOD//3vf5jNZoqLi1m1ahUWi4UVK1Ywf/58PvroIxYtWsS+fftITU3FYrFQUFBAbGwsf/jDH8iNi6NjSAivvvwyN8yYYVQFefsfJDfXaOycORP6+LH9yWSCTz4xqgHHj29e/XhkpNEraPJk4wtm6FDjS/GqqzwdbduwejXMnQsXXhjYS0F36WJUf910kzED9o03+jsinwiKpLLwgoUtPobNYeNw6WHyyvNwKidmMbPnyB5irDG0D2tPePip2O0lVFVlUFW1j759w8nJyeLQoUPk5uYSGxtL9+7dqaiq4PZ7bufnn35GRMjNyqWDswNJcfX/Mq1rivzc3Nw6p7Cva7r7xkybNg2za52QoqIirr/+enbu3ImIYHP18FqxYgW33HILFovluPNde+21vPXuu8yeNYvVmzfzRr9+RiN+XJzxZRka6p0E8/e/GxNe+rOUUqNbN+PSUlddBaNGwW9/a0xy+M03xq/ZSJ+2o7ZuWVlGSbF7d3j77cBf/+aGG4zp8e+5By6+uEXTIbUWfkkqInIB8A/ADPxXKfWkP+KoLcQcQo/2PUiMTqS4upjCykIKKwspqChAENqFtTMSjPVUxFlCVVUmU6ZM4J13niMnp5DfXH4eBwu388pr75KZlcmn331Mj5iuDOw3HGWzoVTd4z4amiK/KaTWF/uJz689tf1DDz3E2WefzZIlS9i3bx9nnXVWg8edPXs2l156KVarlWkzZmA55RRjdHvN7MYWy7HJ+moulhb+WeXlwb//bXzxBtt04klJRo+xv/zFqA77+WdjsJ5rTZ1WQyljap99+2D/fuO6qMiYmDE6uuFLVJRRAmwqm83oBXjkiNHTy9szYnuCyWSUSocMMapA33/f3xF5nc+TioiYgeeAyUAGsFZEPlNKbfF1LHUxmUzEWGOIscaglKK0uvRogtlftB+KIDIkkhhrR66YNoO5t95DTt4RXvzoP2SXl1BVWsIpXeLoHlnFD99+yP79Bygv30ZpaTHgpKQkBRELImZELOTkbKN9eytm8xHS0tazZs0a7PZSRowYyB/+8AO7d28nKSmZgoJ84uJimTTpbP7973/w7LNPAYojRwqIiYmhc+eOpKevpW/fXnz00WKio6Ow2QpxOqux20ux2Y649s+lc+d22GwFvPzy84ATmy2fc84Zywsv/Ivx44e4qr+OEBcXS8eO4XTp0pHHHnuUr75agq1DOMQnI5U2pLwSKa9CyiuQoqKj76GyhhmLX0VGQGQkSjlxOqtdr9uNL5O//91YZa8ZCx85nXaUqsLpPHap675STkBc8YjrtmB0iDz5ttEIaUcpW62LHafTVs82O1DTXV8Bqtb4JwVz2hE28HfE3/k+5tEjKLznfGwj+mKKbI8pMtZ1icccFY85qgNmaxxmc7RvJkBVyuj5d2LSqLmuud2SXoGRkcfmnouJMS513a697a23jGWf337b6FHX4EtwopTD9Zm5fzH+RipxOitc17VvH9vmcBi3RQSzOcp1ia77dmIUofPmEvKXZ3BePQO56BKkssr4Gy8vN97Hmtt1bZs922sJtLEf+CISBrwBDAfygauUUvsaOqY/SiqjgF1KqT0AIvIecBkQEEmlNhEhOiya6LBoEtslUmmv5EjlEQorC8ksycTULYb84lLiO3fk1O696BrdhTvn/JEpU37DGWdcz+mnD6Vv396EhiYQGpoACCEh8bX+iB1MmjSSl156k8GDx9O79ymMHDmA6upMoqK6sHDhvVx++RScTkXHjrF8+ulz3HXXFP74x6cYNGgQZrOZefN+x5Qp5/DwwzczZcpv6NAhlmHDTqOsrJjKyl04HMXYbNlUVu4GYO7cK7jllof561+f4LzzxqOUncrKvfz2t+PZujWFYcPGEBJi4frrp3LzzdMBuPLKieTkZJKUZKaycpfrzQEiXRcAB5grjYupsgpzURWmAqO9R/LyYOhAnCZQJsAEygzKJK7bAiY5ui0s286RSVHsLLoE1jhdCaD2tTrhvhOlqnE6q4BWtKZFFwj5D/R9Cjr89Uvgy3p3VSZwhIE9DJxhJlSYGUx1VDs2NOzMqRAHiEO5LoCj1jYnx7bXwRYtVHUxUdlFqBwAlZ3NVHZWVHZxUtkF7JFgqgRLBZjLj10stW8ffawMS3kZ5rLDhJQK5n2CpVRhKQVLqcJkrzuGw1e1Y1/Sn1D/u+/o/xE4jvufOj6he55IKCaTFZMpHHDicJTidJ68uN5xzxkHI3pCxNTLkSaGVnlWf6yxFzQ73npjcu8H/o3AEaVULxGZAfwNaLAx0OeDH0XkSuACpdTvXPevBUYrpW47Yb85wByA0NDQ4VVVVccdx2PTqTdTlb2KoqoiKmwVdIjoQGRoy+rFjc/BUevXlaPWPw0c+/V8/OX4bbX34+j949V3v66/A2Pb7bffzdChQ7jhhutOiLfm4jzufs1tsdmgrIodO/eT+PbDxq9fhwMc9lq3HWCvue0EpwNlgtxbB2Pv0Q4wuUoTplqlipO3mUyhiIRhMh27NHTfKIXUjtnZyG1BJAQRCyZTiOt2iKv0FVJrm+Xo9fGfxfGf03Gfm1Kwbj3O/MM4ywpwlhWiyotwlhehyktQpSVQUYqqKDPamcoroKqyyaP1lVnALK5rE8osKItx29hubMMiKJPgjA7Fltgee0I77AkxqHbhrtdlPq60XXN9bNibqvP6uJIacOwHgaNWcnCgnHaorMZUUoGpuAIprsRUXAmiKB/bDbGE1oqhdhx13Q45YVv9FzC7/j7CMZmsmM3hruRhPbrN+Ds6uR1HKQcORxkORwkORykORyl2+7HbDkcJ7N5H5Ps/4wwRlNWM02rGGW7GaTXhtJpwhJlQESYcYYLTKjit4AgTkgYvJCw8oUmfdY2GBj+KyFhggVLqfNf9P7k+pydq7bPMtc9qMd6kLKCjaiBxBGxDvVJqEbAIjBH1fg7nJGGWMDpZOnnseMaXTM0ft3uLd/nC8OHDiYyM5Nln/4HZ3MS4QoFIMOVX0v75H5r01Jimnan1GzOBAG9y1hogYsZiaYfF0q7+nboBE3wWUg2LiKyrdX+R67sVIAE4WOuxDGD0Cc8/uo9Syi4iRUA8kFfvCVscctNlAt1r3U90bdMCkE/WnNc0zVvsSqkRvjyhP6ZpWQv0FpEkEQkFZgCfNedAvq6605pOf0aaFrDc+YF/dB9X9Vd7jAb7evk8qSij8vQ2YBmwFVislNrc1ONYrVby8/P1l1YAU0qRn5+PtYUTUmqa5hXu/MD/DLjedftK4LuG2lOgFc9SbLPZyMjIaNaYDs13rFYriYmJhIQE2FT/mtYGNDZLsYhcBCzE6FL8ilLqcRF5BFinlPpMRKzAm8AwoACYUdNzt95jttakommapjVMT32vaZqmtWo6qWiapmkeo5OKpmma5jGtok1FRJxAw/Mg1M8C1DPpQ9DSr7lt0K85+LX09YYrpXxaeGgVSaUlRGSdrwf/+Jt+zW2Dfs3BrzW+Xl39pWmapnmMTiqapmmax7SFpLKo8V2Cjn7NbYN+zcGv1b3eoG9T0TRN03ynLZRUNE3TNB/RSUXTNE3zmKBOKiJygYhsF5FdIjLP3/H4gojsE5F0EUk9YXGeoCEir4hIjohsqrUtTkSWi8hO17V3FvX2g3pe7wIRyXR9zqmuiQGDhoh0F5HvRWSLiGwWkTtc24P5c67vNbeqzzpo21Rc6y/voNb6y8DME9ZfDjoisg8YoZSqd2W21k5EJgKlwBtKqYGubU8BBUqpJ10/IGKVUvf7M05Pqef1LgBKlVLP+DM2bxGRrkBXpdQGEYkG1gNTgVkE7+dc32ueTiv6rIO5pDIK2KWU2qOUqgbeAy7zc0yaByilfsSYhru2y4DXXbdfx/hnDAr1vN6gppQ6rJTa4LpdgrH2UgLB/TnX95pblWBOKnWtv9zqPqBmUMA3IrJeROb4Oxgf6qyUOuy6nQV09mcwPnKbiKS5qseCphroRCLSE2M9j19oI5/zCa8ZWtFnHcxJpa0ar5Q6HbgQuNVVddKmuFamC8563WNeAE4FhgKHgb/7NRovEZEo4CPgTqVUce3HgvVzruM1t6rPOpiTijvrLwcdpVSm6zoHWIJRDdgWZLvqpGvqpnP8HI9XKaWylVIOpZQTeIkg/JxFJATjy/VtpdTHrs1B/TnX9Zpb22cdzEnFnfWXg4qIRLoa+BCRSOA8YFPDzwoatdfSvh741I+xeF3NF6vLbwiyz1lEBHgZ2KqUerbWQ0H7Odf3mlvbZx20vb+g7vWX/RuRd4lIMkbpBIwps98JxtcsIu8CZwEdgGzgYeATYDHQA9gPTFdKBUXjdj2v9yyM6hAF7ANurtXW0OqJyHhgFZAOOF2b52O0MQTr51zfa55JK/qsgzqpaJqmab4VzNVfmqZpmo/ppKJpmqZ5jE4qmqZpmsfopKJpmqZ5jE4qmqZpmsfopKJpXiYiZ4nI5/6OQ9N8QScVTdM0zWN0UtE0FxG5RkR+da1Z8R8RMYtIqYj8n2t9i29FpKNr36EissY1yd+Smkn+RKSXiKwQkY0iskFETnUdPkpEPhSRbSLytmv0tKYFHZ1UNA0QkdOAq4BxSqmhgAO4GogE1imlBgA/YIxmB3gDuF8pNRhjBHTN9reB55RSQ4AzMCYABGPG2TuB/kAyMM7LL0nT/MLi7wA0LUBMAoYDa12FiHCMyQqdwPuufd4CPhaR9kCMUuoH1/bXgQ9c864lKKWWACilKgFcx/tVKZXhup8K9AR+8vqr0jQf00lF0wwCvK6U+tNxG0UeOmG/5s5rVFXrtgP9v6cFKV39pWmGb4ErRaQTHF0L/RSM/5ErXfv8FvhJKVUEHBGRCa7t1wI/uFbryxCRqa5jhIlIhC9fhKb5m/61pGmAUmqLiDyIsWqmCbABtwJlwCjXYzkY7S5gTLv+oitp7AFmu7ZfC/xHRB5xHWOaD1+GpvmdnqVY0xogIqVKqSh/x6FprYWu/tI0TdM8RpdUNE3TNI/RJRVN0zTNY3RS0TRN0zxGJxVN0zTNY3RS0TRN0zxGJxVN0zTNY/4fUHpgtvh+2pMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label = 'train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label = 'val loss')\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label = 'train accuracy')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label = 'val accuracy')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_xlabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc = 'upper left')\n",
    "acc_ax.legend(loc = 'lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/resnetArcfacetModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/resnetArcfacetModel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../model/resnetArcfacetModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9695e1afe6bd24ab3d12bcdaf245765a6ca7df3556ff5963a8b1ba99ba27e5c0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
